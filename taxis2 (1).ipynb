{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import linear_model\nfrom sklearn.model_selection import KFold\nfrom itertools import combinations\nfrom sklearn.feature_selection import SelectKBest, f_classif\n!pip install meteostat\nfrom meteostat import Point, Daily\nimport missingno as msno\nimport calendar\nfrom datetime import datetime\n%load_ext memory_profiler","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:18:33.132922Z","iopub.execute_input":"2021-11-08T00:18:33.133278Z","iopub.status.idle":"2021-11-08T00:18:42.600950Z","shell.execute_reply.started":"2021-11-08T00:18:33.133242Z","shell.execute_reply":"2021-11-08T00:18:42.600122Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"from meteostat import Hourly\n# import warnings\n# warnings.simplefilter('ignore')\nimport gc\nimport subprocess\nimport dask\nimport dask.dataframe as dd","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:18:42.613228Z","iopub.execute_input":"2021-11-08T00:18:42.613566Z","iopub.status.idle":"2021-11-08T00:18:42.626625Z","shell.execute_reply.started":"2021-11-08T00:18:42.613524Z","shell.execute_reply":"2021-11-08T00:18:42.625910Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"In the function below we'll import our data. Given the size of the data we're going to use a bit of a different approach than regular 'pd.read_csv':\n\n* the sheers size of 1 file prevents us from downloading all the 12 files and merging them into one dataframe - we will have to sample 10% of each file, and merge all the sample into 1 massive dataframe\n    * the 10 % is just a number we'll set for now, but our imports function will have an option to change that at the input stage\n* reading only 1 file is already a big task - we'll split that process into 'chunks' and merge all chunks together after all of them are ready\n* every file represents 1 month of trips data, sort of... unfortunatelly it's common to come across dates that are out of range for their files, we can find some unnaturally long trips etc.\n    * this creates our first problem: we will have to do some basic data cleaning (steps 1-3) before we'll start sampling the dataframe, this will prevent us from sampling incorrect/ dirty/ null data, the tradeof: we're going to work on a full size file, which uses a lot of memory\n* we'll try to downcast numeric columns whenever possible to save memory\n\nAll of the above steps are going to be conducted inside a function - to prevent memory leaks. This method creates a new scope for the intermediate variables and removes them automatically when the interpreter exits the function.\n","metadata":{}},{"cell_type":"code","source":"months = []\n# we'll import the data inside a function to save memory:\ndef imports2(year,months_number,sample_part):\n    df_list = []\n    for el in list((range(1,months_number+1))):\n        month = str(el).zfill(2)\n        link = 'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_'+str(year)+'-'+month+'.csv'\n        chunks = pd.read_csv(link, dtype={'tolls_amount': 'float64', 'RatecodeID':'float64',\n                                                           'trip_distance':'float64','store_and_fwd_flag':'category'}, chunksize=40000)\n        df = pd.concat(chunks, ignore_index=True)\n        del chunks\n        gc.collect()\n        # 1. remove nulls and insanely long trips:\n        df = df[~df['payment_type'].isnull()]\n        df = df[df['trip_distance']<500]\n        # 2. create a pickup date column, modify column dtypes:\n        df['pickup_date'] = df['tpep_pickup_datetime'].str[:11]\n        df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n        df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n        df['pickup_date'] = pd.to_datetime(df['pickup_date'])\n        # 3. lets make sure that the dataframe has only this months days:\n        df = df[(df['pickup_date']>=str(year)+'-'+month+'-01') & (df['pickup_date']<=str(year)+'-'+month+'-'+str(calendar.monthrange(year, el)[1]))].copy()\n        # 4. now lets sample only 20% of the original dataset:\n        df = df.sample(int(len(df)*sample_part))\n        # 5. change a few columns to integers to save memory:\n        integerize = ['passenger_count','VendorID','RatecodeID', 'payment_type']\n        for col in integerize:\n            df[col] = df[col].astype(int)\n            df[col] = pd.to_numeric(df[col], downcast=\"unsigned\")\n        # 6. new trick:\n        df_list.append(df)\n        del df\n        gc.collect()\n        if len(df_list)>1:\n            df_both = pd.concat([df_list[0],df_list[1]], axis=0)          \n            del df_list[0]\n            del df_list[0]            \n            gc.collect()\n            df_list.append(df_both)\n            del df_both\n            gc.collect()\n    return df_list[0]\n","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:18:42.628584Z","iopub.execute_input":"2021-11-08T00:18:42.628826Z","iopub.status.idle":"2021-11-08T00:18:42.647000Z","shell.execute_reply.started":"2021-11-08T00:18:42.628796Z","shell.execute_reply":"2021-11-08T00:18:42.646182Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"df_2018 = imports2(2017,12,0.1)\ndf_2019 = imports2(2018,12,0.1)\ndf = pd.concat([df_2018,df_2019], axis=0)  \ndel df_2018\ndel df_2019\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:18:44.299653Z","iopub.execute_input":"2021-11-08T00:18:44.300288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:09:02.126741Z","iopub.execute_input":"2021-11-08T00:09:02.127307Z","iopub.status.idle":"2021-11-08T00:09:02.136753Z","shell.execute_reply.started":"2021-11-08T00:09:02.127257Z","shell.execute_reply":"2021-11-08T00:09:02.135592Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.groupby('PULocationID')['passenger_count'].std()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-07T20:21:26.611543Z","iopub.execute_input":"2021-11-07T20:21:26.611767Z","iopub.status.idle":"2021-11-07T20:21:26.647354Z","shell.execute_reply.started":"2021-11-07T20:21:26.611739Z","shell.execute_reply":"2021-11-07T20:21:26.646311Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def feature_eng(df):\n    # trip length\n    df['trip_length'] = df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']\n    df['trip_length'] = df['trip_length'].astype('timedelta64[m]')\n\n    # day of the week\n    df['day_of_week'] = df['pickup_date'].dt.day_name()\n    df['day_of_week'] = df['day_of_week'].astype('category')\n    df['day_of_week'] = df['day_of_week'].cat.codes\n\n    # time of day\n    df['time_of_day'] = df['tpep_pickup_datetime'].dt.hour\n    df['time_of_day'] = df['time_of_day'].astype('category')\n    df['time_of_day'] = df['time_of_day'].cat.codes\n    return df\ndf = feature_eng(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16,8))\nplt.scatter(df.groupby(df['pickup_date'])['passenger_count'].sum().index,df.groupby(df['pickup_date'])['passenger_count'].sum().values )\nax.tick_params(axis = 'x',labelsize=12, rotation=45)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Weather \nlets try importing weather data ...er from somewhere","metadata":{}},{"cell_type":"code","source":"start = df['pickup_date'].min()\nend = df['pickup_date'].max()\n\ndef get_weather(start, end):\n    # Create Point for NYC\n    location = Point(40.785091,-73.968285)\n\n    # Get daily data for 2018\n    data = Daily(location, start, end)\n    data = data.fetch()\n    data = data.drop(columns=['wpgt','tsun'])\n    data['time'] = data.index\n    data = data.rename(columns={'time':'pickup_date'})\n    return data\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = get_weather(start, end)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:09:07.859597Z","iopub.execute_input":"2021-11-08T00:09:07.859937Z","iopub.status.idle":"2021-11-08T00:09:15.672791Z","shell.execute_reply.started":"2021-11-08T00:09:07.859906Z","shell.execute_reply":"2021-11-08T00:09:15.672072Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def data_merge(data,df):\n    df2=df.merge(data, on='pickup_date', how='left') \n    df2.head()\n    del df\n    del data\n    gc.collect()\n    return df2\ndf2 = data_merge(data,df)\ndel data\ndel df\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df2)","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:09:17.662464Z","iopub.execute_input":"2021-11-08T00:09:17.662706Z","iopub.status.idle":"2021-11-08T00:09:17.670978Z","shell.execute_reply.started":"2021-11-08T00:09:17.662677Z","shell.execute_reply":"2021-11-08T00:09:17.669703Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"WORKS!","metadata":{}},{"cell_type":"code","source":"def iqring(df, col):\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n    df2 = df[~((df[col] < (Q1 - 1.5 * IQR)) |(df[col] > (Q3 + 1.5 * IQR)))]\n    return df2\ndf3 = iqring(df2, 'total_amount')\ndel df2\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def col_dummy(df, col):\n    cols_before = df.columns\n    df[col] = df[col].astype('category')\n    df[col] = df[col].cat.codes\n    hood_series = pd.get_dummies(df[col],prefix=col)\n    df = pd.concat([df, hood_series], axis=1)\n    df = df.drop(columns=(col), axis=1)\n    cols_after = df.columns\n    new_cols = list(set(cols_after) - set(cols_before) )\n    return df, new_cols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test(df, features):\n    np.random.seed(1)\n    shuffled_index = np.random.permutation(df.index)\n    df = df.reindex(index = shuffled_index)\n    split_loc = int(0.5*len(df))\n    # split\n    train = df.iloc[:split_loc].copy()\n    test = df.iloc[split_loc:].copy()\n    del df\n    gc.collect()\n    lr = linear_model.LinearRegression()\n    lr.fit(train[features], train[\"total_amount\"])\n    predictions = lr.predict(test[features])\n    mse = mean_squared_error(test[\"total_amount\"], predictions)\n    rmse = np.sqrt(mse)\n    \n    return rmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test1(df, features):\n#     np.random.seed(1)\n#     shuffled_index = np.random.permutation(df.index)\n#     df = df.reindex(index = shuffled_index)\n#     split_loc = int(0.5*len(df))\n    # split\n    train = df[df['pickup_date'] < '2018-01-01'].copy()\n    test = df[df['pickup_date'] >= '2018-01-01'].copy()\n    del df\n    gc.collect()\n    lr = linear_model.LinearRegression()\n    lr.fit(train[features], train[\"total_amount\"])\n    predictions = lr.predict(test[features])\n    mse = mean_squared_error(test[\"total_amount\"], predictions)\n    rmse = np.sqrt(mse)\n    \n    return rmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext memory_profiler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features1 = ['trip_distance', 'trip_length']\n%memit rmse = train_test(df3, features1)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T23:20:09.395660Z","iopub.execute_input":"2021-11-07T23:20:09.395977Z","iopub.status.idle":"2021-11-07T23:20:18.759350Z","shell.execute_reply.started":"2021-11-07T23:20:09.395944Z","shell.execute_reply":"2021-11-07T23:20:18.758612Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"features1 = ['trip_distance', 'trip_length']\n%memit rmse = train_test1(df3, features1)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T23:20:47.700157Z","iopub.execute_input":"2021-11-07T23:20:47.700463Z","iopub.status.idle":"2021-11-07T23:20:53.132443Z","shell.execute_reply.started":"2021-11-07T23:20:47.700429Z","shell.execute_reply":"2021-11-07T23:20:53.131658Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"features1 = ['trip_distance', 'trip_length']\nrmse = train_test(df3, features1)\n# f1 2.6936316597764085\nrmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features1 = ['trip_distance', 'trip_length']\nrmse = train_test1(df3, features1)\n# f1 2.6936316597764085\nrmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features2 = ['trip_distance', 'trip_length', 'day_of_week', 'time_of_day']\nrmse = train_test(df3, features2)\n# f2 2.671386816892119\nrmse","metadata":{"execution":{"iopub.status.busy":"2021-11-07T23:23:59.570700Z","iopub.execute_input":"2021-11-07T23:23:59.571020Z","iopub.status.idle":"2021-11-07T23:24:04.177949Z","shell.execute_reply.started":"2021-11-07T23:23:59.570982Z","shell.execute_reply":"2021-11-07T23:24:04.176942Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"features2 = ['trip_distance', 'trip_length', 'day_of_week', 'time_of_day']\nrmse = train_test1(df3, features2)\n# f2 3.48\nrmse","metadata":{"execution":{"iopub.status.busy":"2021-11-07T23:21:31.370657Z","iopub.execute_input":"2021-11-07T23:21:31.370957Z","iopub.status.idle":"2021-11-07T23:21:34.650036Z","shell.execute_reply.started":"2021-11-07T23:21:31.370925Z","shell.execute_reply":"2021-11-07T23:21:34.648988Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"features3 = ['trip_length', 'day_of_week', 'time_of_day']\nrmse = train_test(df3, features3)\nrmse","metadata":{"execution":{"iopub.status.busy":"2021-11-07T23:24:27.300873Z","iopub.execute_input":"2021-11-07T23:24:27.301160Z","iopub.status.idle":"2021-11-07T23:24:31.724754Z","shell.execute_reply.started":"2021-11-07T23:24:27.301123Z","shell.execute_reply":"2021-11-07T23:24:31.723893Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"features4 = ['trip_length']\nrmse = train_test(df3, features4)\n# f4 5.548512496765388\nrmse","metadata":{"execution":{"iopub.status.busy":"2021-11-07T20:29:49.743592Z","iopub.execute_input":"2021-11-07T20:29:49.744105Z","iopub.status.idle":"2021-11-07T20:29:53.804858Z","shell.execute_reply.started":"2021-11-07T20:29:49.744056Z","shell.execute_reply":"2021-11-07T20:29:53.803956Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"features5 = ['trip_distance', 'trip_length', 'day_of_week', 'time_of_day', 'tmin', 'tmax']\nrmse = train_test(df3, features5)\n# f5 2.6680336382474628\nrmse","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:09:20.318207Z","iopub.execute_input":"2021-11-08T00:09:20.318492Z","iopub.status.idle":"2021-11-08T00:09:27.816843Z","shell.execute_reply.started":"2021-11-08T00:09:20.318462Z","shell.execute_reply":"2021-11-08T00:09:27.815825Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"%memit rmse = train_test(df3, features5)\n#1318","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:16:04.144513Z","iopub.execute_input":"2021-11-08T00:16:04.144859Z","iopub.status.idle":"2021-11-08T00:16:12.355014Z","shell.execute_reply.started":"2021-11-08T00:16:04.144825Z","shell.execute_reply":"2021-11-08T00:16:12.353574Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"features5 = ['trip_distance', 'trip_length', 'day_of_week', 'time_of_day', 'tmin', 'tmax']\nrmse = train_test1(df3, features5)\n# f 5 3.4780707610134134\nrmse","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:09:36.591283Z","iopub.execute_input":"2021-11-08T00:09:36.591655Z","iopub.status.idle":"2021-11-08T00:09:42.400646Z","shell.execute_reply.started":"2021-11-08T00:09:36.591613Z","shell.execute_reply":"2021-11-08T00:09:42.399638Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"%memit rmse = train_test1(df3, features5)\n#  1842.56 MiB","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:09:42.403084Z","iopub.execute_input":"2021-11-08T00:09:42.403831Z","iopub.status.idle":"2021-11-08T00:09:50.410557Z","shell.execute_reply.started":"2021-11-08T00:09:42.403770Z","shell.execute_reply":"2021-11-08T00:09:50.409243Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df3, new_cols = col_dummy(df3, 'day_of_week')","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:11:42.003078Z","iopub.execute_input":"2021-11-08T00:11:42.004441Z","iopub.status.idle":"2021-11-08T00:11:45.623941Z","shell.execute_reply.started":"2021-11-08T00:11:42.004383Z","shell.execute_reply":"2021-11-08T00:11:45.622485Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"\nfeatures6 = ['trip_distance', 'trip_length', 'time_of_day', 'tmin', 'tmax'] + new_cols\nrmse = train_test(df3, features6)\n# f6 2.634177334931782\nrmse","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:16:41.565567Z","iopub.execute_input":"2021-11-08T00:16:41.565987Z","iopub.status.idle":"2021-11-08T00:16:50.628745Z","shell.execute_reply.started":"2021-11-08T00:16:41.565941Z","shell.execute_reply":"2021-11-08T00:16:50.627727Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"%memit rmse = train_test(df3, features6)\n# 1316","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:17:32.060191Z","iopub.execute_input":"2021-11-08T00:17:32.060524Z","iopub.status.idle":"2021-11-08T00:17:41.553354Z","shell.execute_reply.started":"2021-11-08T00:17:32.060491Z","shell.execute_reply":"2021-11-08T00:17:41.551851Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"\nfeatures6 = ['trip_distance', 'trip_length', 'time_of_day', 'tmin', 'tmax'] + new_cols\nrmse = train_test1(df3, features6)\n# f6 3.4658308154700666\nrmse\n# 2.6013369689567116","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:15:11.577001Z","iopub.execute_input":"2021-11-08T00:15:11.577942Z","iopub.status.idle":"2021-11-08T00:15:15.847126Z","shell.execute_reply.started":"2021-11-08T00:15:11.577839Z","shell.execute_reply":"2021-11-08T00:15:15.846131Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"%memit rmse = train_test1(df3, features6)\n# peak memory: 5329.01 MiB, increment: 2193.05 MiB","metadata":{"execution":{"iopub.status.busy":"2021-11-08T00:17:55.406967Z","iopub.execute_input":"2021-11-08T00:17:55.407313Z","iopub.status.idle":"2021-11-08T00:18:01.183856Z","shell.execute_reply.started":"2021-11-08T00:17:55.407280Z","shell.execute_reply":"2021-11-08T00:18:01.183050Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df3, new_cols2 = col_dummy(df3, 'time_of_day')","metadata":{"execution":{"iopub.status.busy":"2021-11-07T23:27:20.775791Z","iopub.execute_input":"2021-11-07T23:27:20.776098Z","iopub.status.idle":"2021-11-07T23:27:23.229079Z","shell.execute_reply.started":"2021-11-07T23:27:20.776068Z","shell.execute_reply":"2021-11-07T23:27:23.227960Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"\nfeatures7 = ['trip_distance', 'trip_length', 'tmin', 'tmax'] + new_cols + new_cols2\nrmse = train_test(df3, features7)\n# f7 2.5576173097913086\nrmse","metadata":{"execution":{"iopub.status.busy":"2021-11-07T23:27:53.961373Z","iopub.execute_input":"2021-11-07T23:27:53.961887Z","iopub.status.idle":"2021-11-07T23:28:05.192283Z","shell.execute_reply.started":"2021-11-07T23:27:53.961841Z","shell.execute_reply":"2021-11-07T23:28:05.191131Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"\nfeatures7 = ['trip_distance', 'trip_length', 'tmin', 'tmax'] + new_cols + new_cols2\nrmse = train_test1(df3, features7)\n# f7 2.5576173097913086\nrmse","metadata":{"execution":{"iopub.status.busy":"2021-11-07T23:28:26.100222Z","iopub.execute_input":"2021-11-07T23:28:26.100805Z","iopub.status.idle":"2021-11-07T23:28:35.363015Z","shell.execute_reply.started":"2021-11-07T23:28:26.100760Z","shell.execute_reply":"2021-11-07T23:28:35.362046Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df3['total_amount'].mean()","metadata":{"execution":{"iopub.status.busy":"2021-11-07T11:35:40.270059Z","iopub.execute_input":"2021-11-07T11:35:40.270470Z","iopub.status.idle":"2021-11-07T11:35:40.288031Z","shell.execute_reply.started":"2021-11-07T11:35:40.270417Z","shell.execute_reply":"2021-11-07T11:35:40.287100Z"},"jupyter":{"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df3.columns","metadata":{"execution":{"iopub.status.busy":"2021-11-07T11:45:21.643324Z","iopub.execute_input":"2021-11-07T11:45:21.643715Z","iopub.status.idle":"2021-11-07T11:45:21.650839Z","shell.execute_reply.started":"2021-11-07T11:45:21.643677Z","shell.execute_reply":"2021-11-07T11:45:21.649876Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def train_test2(df, features):\n    np.random.seed(1)\n    shuffled_index = np.random.permutation(df.index)\n    df = df.reindex(index = shuffled_index)\n    split_loc = int(0.5*len(df))\n    # split\n    train = df.iloc[:split_loc].copy()\n    test = df.iloc[split_loc:].copy()\n    del df\n    gc.collect()\n    lr = linear_model.LinearRegression()\n    lr.fit(train[features], train[\"total_amount\"])\n    predictions = lr.predict(test[features])\n    mse = mean_squared_error(test[\"total_amount\"], predictions)\n    rmse = np.sqrt(mse)\n    test['predicted'] = predictions\n    \n    return rmse, test","metadata":{"execution":{"iopub.status.busy":"2021-11-07T11:36:44.839411Z","iopub.execute_input":"2021-11-07T11:36:44.839807Z","iopub.status.idle":"2021-11-07T11:36:44.849106Z","shell.execute_reply.started":"2021-11-07T11:36:44.839771Z","shell.execute_reply":"2021-11-07T11:36:44.848391Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"features4 = ['trip_distance', 'trip_length', 'day_of_week', 'time_of_day']\nrmse, test_df = train_test2(df3, features4)\ntest_df[['total_amount', 'predicted']]","metadata":{"execution":{"iopub.status.busy":"2021-11-07T11:44:33.179885Z","iopub.execute_input":"2021-11-07T11:44:33.180443Z","iopub.status.idle":"2021-11-07T11:44:38.032318Z","shell.execute_reply.started":"2021-11-07T11:44:33.180405Z","shell.execute_reply":"2021-11-07T11:44:38.031309Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"df3.groupby('pickup_date')['passenger_count'].sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-07T11:53:34.589249Z","iopub.execute_input":"2021-11-07T11:53:34.589817Z","iopub.status.idle":"2021-11-07T11:53:34.744358Z","shell.execute_reply.started":"2021-11-07T11:53:34.589778Z","shell.execute_reply":"2021-11-07T11:53:34.743702Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"df3.to_csv('myfirst.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-07T23:42:46.466263Z","iopub.execute_input":"2021-11-07T23:42:46.466819Z","iopub.status.idle":"2021-11-07T23:46:33.174736Z","shell.execute_reply.started":"2021-11-07T23:42:46.466766Z","shell.execute_reply":"2021-11-07T23:46:33.173736Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"2+2","metadata":{"execution":{"iopub.status.busy":"2021-11-07T23:46:33.176243Z","iopub.execute_input":"2021-11-07T23:46:33.176466Z","iopub.status.idle":"2021-11-07T23:46:33.185666Z","shell.execute_reply.started":"2021-11-07T23:46:33.176438Z","shell.execute_reply":"2021-11-07T23:46:33.184645Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}